{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMS Spam Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "# Models \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Data Processing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from transformers import pipeline\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_class_imbalance(df:pd.DataFrame, target:pd.Series, col:str):\n",
    "  counter = Counter(target)\n",
    "  for k,v in counter.items():\n",
    "    per = v/len(target) * 100\n",
    "    print(\"Class=%s, Count=%d, Percentage=%.3f%%\" % (k,v, per))\n",
    "  \n",
    "  ax = df[col].value_counts().sort_index().plot(\n",
    "  kind=\"bar\", \n",
    "  title=\"Count of Reviews by Target\", \n",
    "  figsize=(10,5)\n",
    "  )\n",
    "  ax.set_xlabel(col)\n",
    "  plt.show()\n",
    "  \n",
    "def remove_stop_words(review:str):\n",
    "    word_tokens = \" \".join(word_tokenize(review))\n",
    "    filtered_word_tokens = re.sub(r'[^a-zA-Z\\s]', '', word_tokens).split(\" \")\n",
    "    filtered_sentence = [w.lower().strip() for w in filtered_word_tokens if not w.lower() in ENGLISH_STOP_WORDS]\n",
    "    return ' '.join(filtered_sentence).strip()\n",
    "def evaluate_model(X, y, model):\n",
    "  cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "  \n",
    "  metric = make_scorer(f1_score)\n",
    "  scores = cross_val_score(model, X, y, scoring=metric, cv=cv, n_jobs=-1)\n",
    "  return scores\n",
    "\n",
    "def testing_selected_models(names:list, models:list, X:pd.DataFrame, y:pd.Series):\n",
    "    \"\"\"\n",
    "    Runs multiple subsets on folds of data\n",
    "\n",
    "    Args:\n",
    "        names (list): _description_\n",
    "        models (list): _description_\n",
    "    \"\"\"\n",
    "    model_performance = []\n",
    "    for i in range(len(models)):\n",
    "        model = models[i]\n",
    "        # Evaluate the model\n",
    "        scores = evaluate_model(X, y, model)\n",
    "        # summarize and store\n",
    "        model_performance.append({\n",
    "            \"Model\": names[i],\n",
    "            \"Mean\": np.mean(scores),\n",
    "            \"STD\":np.std(scores)\n",
    "        })\n",
    "    performance_df = pd.DataFrame(model_performance)\n",
    "    return performance_df.sort_values(by=\"Mean\", ascending=False)\n",
    "def get_selected_models(names):\n",
    "  \"\"\"\n",
    "  Returns selected models for ML processing\n",
    "\n",
    "  Args:\n",
    "      names (_type_):List\n",
    "\n",
    "  Returns:\n",
    "      List of models\n",
    "  \"\"\"\n",
    "  models = {\n",
    "    \"LDA\": LinearDiscriminantAnalysis(),\n",
    "    \"GPC\": GaussianProcessClassifier(),\n",
    "    \"GNB\": GaussianNB(),\n",
    "    \"SVC\": SVC(),\n",
    "    \"LR\":LogisticRegression(max_iter=1000),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"DTC\": DecisionTreeClassifier(),\n",
    "    \"GBC\":GradientBoostingClassifier(),\n",
    "    \"RFC\":RandomForestClassifier(),\n",
    "    \"XGB\": XGBClassifier(),\n",
    "    \"MN\": MultinomialNB()\n",
    "  }\n",
    "  \n",
    "  return [models[model] for model in names]\n",
    "\n",
    "def testing_selected_models(names:list, models:list, X:pd.DataFrame, y:pd.Series):\n",
    "    \"\"\"\n",
    "    Runs multiple subsets on folds of data\n",
    "\n",
    "    Args:\n",
    "        names (list): _description_\n",
    "        models (list): _description_\n",
    "    \"\"\"\n",
    "    model_performance = []\n",
    "    for i in range(len(models)):\n",
    "        model = models[i]\n",
    "        scores = evaluate_model(X, y, model)\n",
    "        model_performance.append({\n",
    "            \"Model\": names[i],\n",
    "            \"Mean\": np.mean(scores),\n",
    "            \"STD\":np.std(scores)\n",
    "        })\n",
    "    performance_df = pd.DataFrame(model_performance)\n",
    "    return performance_df.sort_values(by=\"Mean\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  EDA Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        v1                                                 v2\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham              Will Ì_ b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/Users/maukanmir/Downloads/spam_sms.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = [\"target\", \"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     target                                               text\n",
       "0       ham  Go until jurong point, crazy.. Available only ...\n",
       "1       ham                      Ok lar... Joking wif u oni...\n",
       "2      spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3       ham  U dun say so early hor... U c already then say...\n",
       "4       ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...     ...                                                ...\n",
       "5567   spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568    ham              Will Ì_ b going to esplanade fr home?\n",
       "5569    ham  Pity, * was in mood for that. So...any other s...\n",
       "5570    ham  The guy did some bitching but I acted like i'd...\n",
       "5571    ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check for Nulls and Dupes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null Count: target    0\n",
      "text      0\n",
      "dtype: int64\n",
      "Dupe Count: 403\n"
     ]
    }
   ],
   "source": [
    "print(f\"Null Count: {df.isna().sum()}\")\n",
    "print(f\"Dupe Count: {df.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# There are 403 cases of duplicates, however they all could be spam, we have to do more EDA before dropping these values. These duplicates could be relevant information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     309\n",
       "spam     94\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.duplicated()][\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sorry, I'll call later                                                                                                                                                                                                                                                                                                                       29\n",
       "I cant pick the phone right now. Pls send a message                                                                                                                                                                                                                                                                                          11\n",
       "Ok...                                                                                                                                                                                                                                                                                                                                         9\n",
       "Ok                                                                                                                                                                                                                                                                                                                                            3\n",
       "7 wonders in My WORLD 7th You 6th Ur style 5th Ur smile 4th Ur Personality 3rd Ur Nature 2nd Ur SMS and 1st \\Ur Lovely Friendship\\\"... good morning dear\"                                                                                                                                                                                     3\n",
       "                                                                                                                                                                                                                                                                                                                                             ..\n",
       "URGENT! We are trying to contact U. Todays draw shows that you have won a å£800 prize GUARANTEED. Call 09050001808 from land line. Claim M95. Valid12hrs only                                                                                                                                                                                 1\n",
       "Easy ah?sen got selected means its good..                                                                                                                                                                                                                                                                                                     1\n",
       "No:-)i got rumour that you going to buy apartment in chennai:-)                                                                                                                                                                                                                                                                               1\n",
       "Still i have not checked it da. . .                                                                                                                                                                                                                                                                                                           1\n",
       "I know you are thinkin malaria. But relax, children cant handle malaria. She would have been worse and its gastroenteritis. If she takes enough to replace her loss her temp will reduce. And if you give her malaria meds now she will just vomit. Its a self limiting illness she has which means in a few days it will completely stop     1\n",
       "Name: text, Length: 281, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.duplicated()][\"text\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interesting here, of the 403 dupes 309 are labeled as real emails while 94 as spam. Lets check if the same message is being labeled as both spam and ham in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dupe_df = df[df.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_df = dupe_df[dupe_df['target'] == 'spam']\n",
    "ham_df = dupe_df[dupe_df['target'] == 'ham']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ham_series_text = ham_df[\"text\"]\n",
    "spam_series_text = spam_df['text']\n",
    "\n",
    "dupe_texts = [text for text in ham_series_text if text in spam_series_text]\n",
    "dupe_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The same message is not in spam or ham which is a good sign of data quality other than the dupes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
